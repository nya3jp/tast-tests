{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "d4b2795d_4c5b4f42",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1111649
      },
      "writtenOn": "2021-07-23T17:33:27Z",
      "side": 1,
      "message": "Adding Madhulika due to the bitrate commit comments. We were discussing video.EncodeAccel.h264_2160p TGL results yesterday. Madhulika did you happen to file a ticket?",
      "revId": "8873210c32e97e94f85a0d23a7c1984e58ed673d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "09390c5b_dd43494b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1113991
      },
      "writtenOn": "2021-07-23T19:07:01Z",
      "side": 1,
      "message": "Thanks. Note that this is using the SW openh264enc binary (not VA-API).\n\nI\u0027m not sure if the bitrate error comes from the fact that I couldn\u0027t\nuse RC_BITRATE_MODE (\u003d\u003d1) because the test is meant to read the input\nfile as fast as possible and clearly the implementation wants the \ninput to follow the expected frame rate : ( \n\nI chose RC_BUFFERBASED_MODE [1] to get reasonable PSNR/SSIM results, \nbut I\u0027m afraid it\u0027s ignoring the input bitrate argument (\"-tarb\") \nin favour of some other internal metric.\n\nCan you guys help with that...?\n\n[1] https://github.com/cisco/openh264/blob/6584567029f8899d5375333228a77517ba0c2b3b/codec/api/svc/codec_app_def.h#L271",
      "parentUuid": "d4b2795d_4c5b4f42",
      "revId": "8873210c32e97e94f85a0d23a7c1984e58ed673d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}