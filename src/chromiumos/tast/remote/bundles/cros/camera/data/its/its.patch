diff --git a/pymodules/its/caps.py b/pymodules/its/caps.py
index 87b88e9..4c4eb78 100644
--- a/pymodules/its/caps.py
+++ b/pymodules/its/caps.py
@@ -34,7 +34,7 @@ def skip_unless(cond):
     SKIP_RET_CODE = 101
 
     if not cond:
-        print "Test skipped"
+        print("Test skipped")
         sys.exit(SKIP_RET_CODE)
 
 def full_or_better(props):
@@ -46,9 +46,8 @@ def full_or_better(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.info.supportedHardwareLevel") and \
-            props["android.info.supportedHardwareLevel"] != 2 and \
-            props["android.info.supportedHardwareLevel"] >= 1
+    return (props.get('android.info.supportedHardwareLevel') >= 1 and
+            props.get('android.info.supportedHardwareLevel') != 2)
 
 def level3(props):
     """Returns whether a device is a LEVEL3 capability camera2 device.
@@ -59,8 +58,7 @@ def level3(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.info.supportedHardwareLevel") and \
-           props["android.info.supportedHardwareLevel"] == 3
+    return props.get("android.info.supportedHardwareLevel") == 3
 
 def full(props):
     """Returns whether a device is a FULL capability camera2 device.
@@ -71,8 +69,7 @@ def full(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.info.supportedHardwareLevel") and \
-           props["android.info.supportedHardwareLevel"] == 1
+    return props.get("android.info.supportedHardwareLevel") == 1
 
 def limited(props):
     """Returns whether a device is a LIMITED capability camera2 device.
@@ -83,8 +80,7 @@ def limited(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.info.supportedHardwareLevel") and \
-           props["android.info.supportedHardwareLevel"] == 0
+    return props.get("android.info.supportedHardwareLevel") == 0
 
 def legacy(props):
     """Returns whether a device is a LEGACY capability camera2 device.
@@ -95,8 +91,7 @@ def legacy(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.info.supportedHardwareLevel") and \
-           props["android.info.supportedHardwareLevel"] == 2
+    return props.get("android.info.supportedHardwareLevel") == 2
 
 def distortion_correction(props):
     """Returns whether a device supports DISTORTION_CORRECTION
@@ -108,8 +103,8 @@ def distortion_correction(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.lens.distortion") and \
-           props["android.lens.distortion"] is not None
+    return 'android.lens.distortion' in props and props[
+           'android.lens.distortion'] is not None
 
 def manual_sensor(props):
     """Returns whether a device supports MANUAL_SENSOR capabilities.
@@ -120,8 +115,7 @@ def manual_sensor(props):
     Returns:
         Boolean.
     """
-    return    props.has_key("android.request.availableCapabilities") and \
-              1 in props["android.request.availableCapabilities"]
+    return 1 in props.get("android.request.availableCapabilities", [])
 
 def manual_post_proc(props):
     """Returns whether a device supports MANUAL_POST_PROCESSING capabilities.
@@ -132,8 +126,7 @@ def manual_post_proc(props):
     Returns:
         Boolean.
     """
-    return    props.has_key("android.request.availableCapabilities") and \
-              2 in props["android.request.availableCapabilities"]
+    return 2 in props.get("android.request.availableCapabilities", [])
 
 def raw(props):
     """Returns whether a device supports RAW capabilities.
@@ -144,8 +137,7 @@ def raw(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.request.availableCapabilities") and \
-           3 in props["android.request.availableCapabilities"]
+    return 3 in props.get("android.request.availableCapabilities", [])
 
 def raw16(props):
     """Returns whether a device supports RAW16 output.
@@ -200,8 +192,10 @@ def post_raw_sensitivity_boost(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.control.postRawSensitivityBoostRange") and \
-            props["android.control.postRawSensitivityBoostRange"] != [100, 100]
+    return props.get("android.control.postRawSensitivityBoostRange") != [
+        100, 100
+    ]
+
 
 def sensor_fusion(props):
     """Returns whether the camera and motion sensor timestamps for the device
@@ -213,8 +207,7 @@ def sensor_fusion(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.sensor.info.timestampSource") and \
-           props["android.sensor.info.timestampSource"] == 1
+    return props.get("android.sensor.info.timestampSource") == 1
 
 def read_3a(props):
     """Return whether a device supports reading out the following 3A settings:
@@ -253,7 +246,7 @@ def freeform_crop(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.scaler.croppingType") and \
+    return "android.scaler.croppingType" in props and \
            props["android.scaler.croppingType"] == 1
 
 def flash(props):
@@ -265,7 +258,7 @@ def flash(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.flash.info.available") and \
+    return "android.flash.info.available" in props and \
            props["android.flash.info.available"] == 1
 
 def per_frame_control(props):
@@ -277,7 +270,7 @@ def per_frame_control(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.sync.maxLatency") and \
+    return "android.sync.maxLatency" in props and \
            props["android.sync.maxLatency"] == 0
 
 def ev_compensation(props):
@@ -289,7 +282,7 @@ def ev_compensation(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.control.aeCompensationRange") and \
+    return "android.control.aeCompensationRange" in props and \
            props["android.control.aeCompensationRange"] != [0, 0]
 
 def ae_lock(props):
@@ -301,7 +294,7 @@ def ae_lock(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.control.aeLockAvailable") and \
+    return "android.control.aeLockAvailable" in props and \
            props["android.control.aeLockAvailable"] == 1
 
 def awb_lock(props):
@@ -313,7 +306,7 @@ def awb_lock(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.control.awbLockAvailable") and \
+    return "android.control.awbLockAvailable" in props and \
            props["android.control.awbLockAvailable"] == 1
 
 def lsc_map(props):
@@ -325,9 +318,8 @@ def lsc_map(props):
     Return:
         Boolean.
     """
-    return props.has_key(
-            "android.statistics.info.availableLensShadingMapModes") and \
-        1 in props["android.statistics.info.availableLensShadingMapModes"]
+    return "android.statistics.info.availableLensShadingMapModes" in props and \
+           1 in props["android.statistics.info.availableLensShadingMapModes"]
 
 def lsc_off(props):
     """Returns whether a device supports disabling lens shading correction
@@ -338,9 +330,8 @@ def lsc_off(props):
     Return:
         Boolean.
     """
-    return props.has_key(
-            "android.shading.availableModes") and \
-        0 in props["android.shading.availableModes"]
+    return "android.shading.availableModes" in props and \
+           0 in props["android.shading.availableModes"]
 
 def yuv_reprocess(props):
     """Returns whether a device supports YUV reprocessing.
@@ -351,7 +342,7 @@ def yuv_reprocess(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.request.availableCapabilities") and \
+    return "android.request.availableCapabilities" in props and \
            7 in props["android.request.availableCapabilities"]
 
 def private_reprocess(props):
@@ -363,7 +354,7 @@ def private_reprocess(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.request.availableCapabilities") and \
+    return "android.request.availableCapabilities" in props and \
            4 in props["android.request.availableCapabilities"]
 
 def noise_reduction_mode(props, mode):
@@ -377,9 +368,8 @@ def noise_reduction_mode(props, mode):
     Returns:
         Boolean.
     """
-    return props.has_key(
-            "android.noiseReduction.availableNoiseReductionModes") and mode \
-            in props["android.noiseReduction.availableNoiseReductionModes"];
+    return "android.noiseReduction.availableNoiseReductionModes" in props and \
+           mode in props["android.noiseReduction.availableNoiseReductionModes"]
 
 def edge_mode(props, mode):
     """Returns whether a device supports the edge mode.
@@ -391,9 +381,8 @@ def edge_mode(props, mode):
     Returns:
         Boolean.
     """
-    return props.has_key(
-            "android.edge.availableEdgeModes") and mode \
-            in props["android.edge.availableEdgeModes"];
+    return "android.edge.availableEdgeModes" in props and \
+           mode in props["android.edge.availableEdgeModes"]
 
 def tonemap_mode(props, mode):
     """Returns whether a device supports the tonemap mode.
@@ -405,9 +394,8 @@ def tonemap_mode(props, mode):
     Return:
         Boolean.
     """
-    return props.has_key(
-            "android.tonemap.availableToneMapModes") and mode \
-            in props["android.tonemap.availableToneMapModes"];
+    return "android.tonemap.availableToneMapModes" in props and \
+           mode in props["android.tonemap.availableToneMapModes"]
 
 def lens_calibrated(props):
     """Returns whether lens position is calibrated or not.
@@ -423,8 +411,8 @@ def lens_calibrated(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.lens.info.focusDistanceCalibration") and \
-         props["android.lens.info.focusDistanceCalibration"] == 2
+    return "android.lens.info.focusDistanceCalibration" in props and \
+           props["android.lens.info.focusDistanceCalibration"] == 2
 
 
 def lens_approx_calibrated(props):
@@ -441,9 +429,7 @@ def lens_approx_calibrated(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.lens.info.focusDistanceCalibration") and \
-        (props["android.lens.info.focusDistanceCalibration"] == 1 or
-         props["android.lens.info.focusDistanceCalibration"] == 2)
+    return props.get("android.lens.info.focusDistanceCalibration") in [1, 2]
 
 
 def fixed_focus(props):
@@ -457,8 +443,7 @@ def fixed_focus(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.lens.info.minimumFocusDistance") and \
-        props["android.lens.info.minimumFocusDistance"] == 0
+    return props.get("android.lens.info.minimumFocusDistance") == 0
 
 def logical_multi_camera(props):
     """Returns whether a device is a logical multi-camera.
@@ -469,7 +454,7 @@ def logical_multi_camera(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.request.availableCapabilities") and \
+    return "android.request.availableCapabilities" in props and \
            11 in props["android.request.availableCapabilities"]
 
 def logical_multi_camera_physical_ids(props):
@@ -495,7 +480,7 @@ def mono_camera(props):
     Return:
         Boolean.
     """
-    return props.has_key("android.request.availableCapabilities") and \
+    return "android.request.availableCapabilities" in props and \
            12 in props["android.request.availableCapabilities"]
 
 
@@ -510,8 +495,8 @@ def face_detect(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.statistics.info.availableFaceDetectModes") and \
-        props["android.statistics.info.availableFaceDetectModes"] != [0]
+    return "android.statistics.info.availableFaceDetectModes" in props and \
+           props["android.statistics.info.availableFaceDetectModes"] != [0]
 
 
 def debug_mode():
@@ -535,8 +520,7 @@ def backward_compatible(props):
     Returns:
         Boolean.
     """
-    return props.has_key("android.request.availableCapabilities") and \
-              0 in props["android.request.availableCapabilities"]
+    return 0 in props.get("android.request.availableCapabilities", [])
 
 
 class __UnitTest(unittest.TestCase):
diff --git a/pymodules/its/cv2image.py b/pymodules/its/cv2image.py
index 2004846..5e58f8f 100644
--- a/pymodules/its/cv2image.py
+++ b/pymodules/its/cv2image.py
@@ -76,7 +76,7 @@ class Chart(object):
                 if its.caps.read_3a(props):
                     self.locate(cam, props)
                 else:
-                    print 'Chart locator skipped.'
+                    print('Chart locator skipped.')
                     self._set_scale_factors_to_one()
 
     def _set_scale_factors_to_one(self):
@@ -114,14 +114,14 @@ class Chart(object):
         focal_l = cap_chart['metadata']['android.lens.focalLength']
         pixel_pitch = (props['android.sensor.info.physicalSize']['height'] /
                        img_3a.shape[0])
-        print ' Chart distance: %.2fcm' % self._distance
-        print ' Chart height: %.2fcm' % self._height
-        print ' Focal length: %.2fmm' % focal_l
-        print ' Pixel pitch: %.2fum' % (pixel_pitch*1E3)
-        print ' Template height: %dpixels' % template.shape[0]
+        print(' Chart distance: %.2fcm' % self._distance)
+        print(' Chart height: %.2fcm' % self._height)
+        print(' Focal length: %.2fmm' % focal_l)
+        print(' Pixel pitch: %.2fum' % (pixel_pitch*1E3))
+        print(' Template height: %dpixels' % template.shape[0])
         chart_pixel_h = self._height * focal_l / (self._distance * pixel_pitch)
         scale_factor = template.shape[0] / chart_pixel_h
-        print 'Chart/image scale factor = %.2f' % scale_factor
+        print('Chart/image scale factor = %.2f' % scale_factor)
         return template, img_3a, scale_factor
 
     def locate(self, cam, props):
@@ -144,7 +144,7 @@ class Chart(object):
             chart, scene, s_factor = self._calc_scale_factors(cam, props, fmt,
                                                               s, e, fd)
         else:
-            print 'Chart locator skipped.'
+            print('Chart locator skipped.')
             self._set_scale_factors_to_one()
             return
         scale_start = self._scale_start * s_factor
@@ -156,7 +156,7 @@ class Chart(object):
         if numpy.amax(scene) <= 1.0:
             scene = (scene * 255.0).astype(numpy.uint8)
         scene_gray = gray_scale_img(scene)
-        print 'Finding chart in scene...'
+        print('Finding chart in scene...')
         for scale in numpy.arange(scale_start, scale_stop, scale_step):
             scene_scaled = scale_img(scene_gray, scale)
             if (scene_scaled.shape[0] < chart.shape[0] or
@@ -165,7 +165,7 @@ class Chart(object):
             result = cv2.matchTemplate(scene_scaled, chart, cv2.TM_CCOEFF)
             _, opt_val, _, top_left_scaled = cv2.minMaxLoc(result)
             # print out scale and match
-            print ' scale factor: %.3f, opt val: %.f' % (scale, opt_val)
+            print(' scale factor: %.3f, opt val: %.f' % (scale, opt_val))
             max_match.append((opt_val, top_left_scaled))
 
         # determine if optimization results are valid
@@ -174,18 +174,18 @@ class Chart(object):
             estring = ('Warning: unable to find chart in scene!\n'
                        'Check camera distance and self-reported '
                        'pixel pitch, focal length and hyperfocal distance.')
-            print estring
+            print(estring)
             self._set_scale_factors_to_one()
         else:
             if (max(opt_values) == opt_values[0] or
                         max(opt_values) == opt_values[len(opt_values)-1]):
                 estring = ('Warning: chart is at extreme range of locator '
                            'check.\n')
-                print estring
+                print(estring)
             # find max and draw bbox
             match_index = max_match.index(max(max_match, key=lambda x: x[0]))
             self.scale = scale_start + scale_step * match_index
-            print 'Optimum scale factor: %.3f' %  self.scale
+            print('Optimum scale factor: %.3f' %  self.scale)
             top_left_scaled = max_match[match_index][1]
             h, w = chart.shape
             bottom_right_scaled = (top_left_scaled[0] + w,
diff --git a/pymodules/its/device.py b/pymodules/its/device.py
index a1de8cf..f38b5cd 100644
--- a/pymodules/its/device.py
+++ b/pymodules/its/device.py
@@ -133,7 +133,7 @@ class ItsSession(object):
 
         port = None
         used_ports = []
-        for line in output.split(os.linesep):
+        for line in output.decode('utf-8').split(os.linesep):
             # each line should be formatted as:
             # "<device_id> tcp:<host_port> tcp:<remote_port>"
             forward_info = line.split()
@@ -164,7 +164,7 @@ class ItsSession(object):
                     output, error = proc.communicate()
 
                     # Check if there is no error
-                    if error is None or error.find("error") < 0:
+                    if error is None or error.find("error".encode()) < 0:
                         port = p
                         break
 
@@ -191,11 +191,11 @@ class ItsSession(object):
                 duration = 30
                 if len(s) > 7 and s[6] == "=":
                     duration = int(s[7:])
-                print "Rebooting device"
+                print("Rebooting device")
                 _run("%s reboot" % (self.adb))
                 _run("%s wait-for-device" % (self.adb))
                 time.sleep(duration)
-                print "Reboot complete"
+                print("Reboot complete")
 
         # Flush logcat so following code won't be misled by previous
         # 'ItsService ready' log.
@@ -214,7 +214,7 @@ class ItsSession(object):
         logcat = proc.stdout
         while True:
             line = logcat.readline().strip()
-            if line.find('ItsService ready') >= 0:
+            if line.find(b'ItsService ready') >= 0:
                 break
         proc.kill()
 
@@ -243,7 +243,7 @@ class ItsSession(object):
         # Read a line (newline-terminated) string serialization of JSON object.
         chars = []
         while len(chars) == 0 or chars[-1] != '\n':
-            ch = self.sock.recv(1)
+            ch = self.sock.recv(1).decode('utf-8')
             if len(ch) == 0:
                 # Socket was probably closed; otherwise don't get empty strings
                 raise its.error.Error('Problem with socket on device side')
@@ -252,7 +252,7 @@ class ItsSession(object):
         jobj = json.loads(line)
         # Optionally read a binary buffer of a fixed size.
         buf = None
-        if jobj.has_key("bufValueSize"):
+        if "bufValueSize" in jobj:
             n = jobj["bufValueSize"]
             buf = bytearray(n)
             view = memoryview(buf)
@@ -275,14 +275,14 @@ class ItsSession(object):
                     if len(camera_ids) == 1:
                         camera_id = camera_ids[0]
         cmd = {"cmdName":"open", "cameraId":camera_id}
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'cameraOpened':
             raise its.error.Error('Invalid command response')
 
     def __close_camera(self):
         cmd = {"cmdName":"close"}
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'cameraClosed':
             raise its.error.Error('Invalid command response')
@@ -305,7 +305,7 @@ class ItsSession(object):
         cmd = {}
         cmd["cmdName"] = "doVibrate"
         cmd["pattern"] = pattern
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'vibrationStarted':
             raise its.error.Error('Invalid command response')
@@ -318,7 +318,7 @@ class ItsSession(object):
         """
         cmd = {}
         cmd["cmdName"] = "checkSensorExistence"
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'sensorExistence':
             raise its.error.Error('Invalid command response')
@@ -334,7 +334,7 @@ class ItsSession(object):
         """
         cmd = {}
         cmd["cmdName"] = "startSensorEvents"
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'sensorEventsStarted':
             raise its.error.Error('Invalid command response')
@@ -362,7 +362,7 @@ class ItsSession(object):
         """
         cmd = {}
         cmd["cmdName"] = "getSensorEvents"
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         timeout = self.SOCK_TIMEOUT + self.EXTRA_SOCK_TIMEOUT
         self.sock.settimeout(timeout)
         data,_ = self.__read_response_from_socket()
@@ -379,7 +379,7 @@ class ItsSession(object):
         """
         cmd = {}
         cmd["cmdName"] = "getCameraIds"
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'cameraIds':
             raise its.error.Error('Invalid command response')
@@ -393,7 +393,7 @@ class ItsSession(object):
         """
         cmd = {}
         cmd["cmdName"] = "getCameraProperties"
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'cameraProperties':
             raise its.error.Error('Invalid command response')
@@ -414,7 +414,7 @@ class ItsSession(object):
         cmd = {}
         cmd["cmdName"] = "getCameraPropertiesById"
         cmd["cameraId"] = camera_id
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
         data,_ = self.__read_response_from_socket()
         if data['tag'] != 'cameraProperties':
             raise its.error.Error('Invalid command response')
@@ -465,7 +465,7 @@ class ItsSession(object):
             * AF focus position; None if do_af is false
             Otherwise, it returns five None values.
         """
-        print "Running vendor 3A on device"
+        print("Running vendor 3A on device")
         cmd = {}
         cmd["cmdName"] = "do3A"
         cmd["regions"] = {"ae": sum(regions_ae, []),
@@ -478,7 +478,7 @@ class ItsSession(object):
             cmd["awbLock"] = True
         if ev_comp != 0:
             cmd["evComp"] = ev_comp
-        self.sock.send(json.dumps(cmd) + "\n")
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
 
         # Wait for each specified 3A to converge.
         ae_sens = None
@@ -741,7 +741,7 @@ class ItsSession(object):
                     raise its.error.Error('Camera props are unavailable')
                 yuv_maxsize_2d = its.objects.get_available_output_sizes(
                     "yuv", self.props)[0]
-                yuv_maxsize_1d = yuv_maxsize_2d[0] * yuv_maxsize_2d[1] * 3 / 2
+                yuv_maxsize_1d = yuv_maxsize_2d[0] * yuv_maxsize_2d[1] * 3 // 2
                 break
         yuv_sizes = [c["width"]*c["height"]*3/2
                      if "width" in c and "height" in c
@@ -753,7 +753,7 @@ class ItsSession(object):
             raise its.error.Error(
                     'ITS does not support yuv outputs of same buffer size')
         if len(logical_cam_formats) > len(set(logical_cam_formats)):
-          if n_yuv != len(logical_cam_formats) - len(set(logical_cam_formats)) + 1:
+            if n_yuv != len(logical_cam_formats) - len(set(logical_cam_formats)) + 1:
                 raise its.error.Error('Duplicate format requested')
 
         raw_formats = 0;
@@ -770,18 +770,18 @@ class ItsSession(object):
         for req in cmd["captureRequests"]:
             if "android.sensor.exposureTime" in req and \
                     req["android.sensor.exposureTime"] > longest_exp_time:
-                longest_exp_time = req["android.sensor.exposureTime"]
+                longest_exp_time = int(req["android.sensor.exposureTime"])
 
-        extended_timeout = longest_exp_time / self.SEC_TO_NSEC + \
+        extended_timeout = longest_exp_time // self.SEC_TO_NSEC + \
                 self.SOCK_TIMEOUT
         if repeat_request:
             extended_timeout += self.EXTRA_SOCK_TIMEOUT
         self.sock.settimeout(extended_timeout)
 
-        print "Capturing %d frame%s with %d format%s [%s]" % (
+        print("Capturing %d frame%s with %d format%s [%s]" % (
                   ncap, "s" if ncap>1 else "", nsurf, "s" if nsurf>1 else "",
-                  ",".join(formats))
-        self.sock.send(json.dumps(cmd) + "\n")
+                  ",".join(formats)))
+        self.sock.send(json.dumps(cmd).encode() + "\n".encode())
 
         # Wait for ncap*nsurf images and ncap metadata responses.
         # Assume that captures come out in the same order as requested in
@@ -840,7 +840,7 @@ class ItsSession(object):
                 if j in physical_cam_ids:
                     obj["data"] = physical_buffers[physical_cam_ids[j]][i]
                 elif fmt == 'yuv':
-                    buf_size = widths[j] * heights[j] * 3 / 2
+                    buf_size = (widths[j] * heights[j] * 3) // 2
                     obj["data"] = yuv_bufs[buf_size][i]
                 else:
                     obj["data"] = bufs[fmt][i]
@@ -882,7 +882,7 @@ def get_device_id():
     command = "adb devices"
     proc = subprocess.Popen(command.split(), stdout=subprocess.PIPE)
     output, error = proc.communicate()
-    for line in output.split(os.linesep):
+    for line in output.decode('utf-8').split(os.linesep):
         device_info = line.split()
         if len(device_info) == 2 and device_info[1] == "device":
             devices.append(device_info[0])
@@ -942,7 +942,7 @@ def report_result(device_id, camera_id, results):
             ItsSession.EXTRA_CAMERA_ID, camera_id,
             ItsSession.EXTRA_RESULTS, json_results)
     if len(cmd) > 4095:
-        print "ITS command string might be too long! len:", len(cmd)
+        print("ITS command string might be too long! len:", len(cmd))
     _run(cmd)
 
 def adb_log(device_id, msg):
@@ -972,14 +972,11 @@ def get_device_fingerprint(device_id):
     com = ('adb -s %s shell getprop | grep ro.build.fingerprint' % device_id)
     proc = subprocess.Popen(com.split(), stdout=subprocess.PIPE)
     output, error = proc.communicate()
+    output = output.decode('utf-8')
     assert error is None
 
-    lst = string.split( \
-            string.replace( \
-            string.replace( \
-            string.replace(output,
-            '\n', ''), '[', ''), ']', ''), \
-            ' ')
+
+    lst = output.replace('\n', '').replace('[', '').replace(']', '').split(' ')
 
     if lst[0].find('ro.build.fingerprint') != -1:
         device_bfp = lst[1]
@@ -1014,4 +1011,3 @@ class __UnitTest(unittest.TestCase):
 
 if __name__ == '__main__':
     unittest.main()
-
diff --git a/pymodules/its/image.py b/pymodules/its/image.py
index 3ea6fa3..5c78bcf 100644
--- a/pymodules/its/image.py
+++ b/pymodules/its/image.py
@@ -21,7 +21,7 @@ from PIL import Image
 import numpy
 import math
 import unittest
-import cStringIO
+import io
 import copy
 import random
 
@@ -34,11 +34,11 @@ DEFAULT_YUV_OFFSETS = numpy.array([0, 128, 128])
 
 DEFAULT_GAMMA_LUT = numpy.array(
         [math.floor(65535 * math.pow(i/65535.0, 1/2.2) + 0.5)
-         for i in xrange(65536)])
+         for i in range(65536)])
 
 DEFAULT_INVGAMMA_LUT = numpy.array(
         [math.floor(65535 * math.pow(i/65535.0, 2.2) + 0.5)
-         for i in xrange(65536)])
+         for i in range(65536)])
 
 MAX_LUT_SIZE = 65536
 
@@ -140,7 +140,7 @@ def unpack_raw10_image(img):
     """
     if img.shape[1] % 5 != 0:
         raise its.error.Error('Invalid raw-10 buffer width')
-    w = img.shape[1]*4/5
+    w = img.shape[1]*4//5
     h = img.shape[0]
     # Cut out the 4x8b MSBs and shift to bits [9:2] in 16b words.
     msbs = numpy.delete(img, numpy.s_[4::5], 1)
@@ -148,11 +148,11 @@ def unpack_raw10_image(img):
     msbs = numpy.left_shift(msbs, 2)
     msbs = msbs.reshape(h,w)
     # Cut out the 4x2b LSBs and put each in bits [1:0] of their own 8b words.
-    lsbs = img[::, 4::5].reshape(h,w/4)
+    lsbs = img[::, 4::5].reshape(h,w//4)
     lsbs = numpy.right_shift(
-            numpy.packbits(numpy.unpackbits(lsbs).reshape(h,w/4,4,2),3), 6)
+            numpy.packbits(numpy.unpackbits(lsbs).reshape(h,w//4,4,2),3), 6)
     # Pair the LSB bits group to 0th pixel instead of 3rd pixel
-    lsbs = lsbs.reshape(h,w/4,4)[:,:,::-1]
+    lsbs = lsbs.reshape(h,w//4,4)[:,:,::-1]
     lsbs = lsbs.reshape(h,w)
     # Fuse the MSBs and LSBs back together
     img16 = numpy.bitwise_or(msbs, lsbs).reshape(h,w)
@@ -194,7 +194,7 @@ def unpack_raw12_image(img):
     """
     if img.shape[1] % 3 != 0:
         raise its.error.Error('Invalid raw-12 buffer width')
-    w = img.shape[1]*2/3
+    w = img.shape[1]*2//3
     h = img.shape[0]
     # Cut out the 2x8b MSBs and shift to bits [11:4] in 16b words.
     msbs = numpy.delete(img, numpy.s_[2::3], 1)
@@ -202,11 +202,11 @@ def unpack_raw12_image(img):
     msbs = numpy.left_shift(msbs, 4)
     msbs = msbs.reshape(h,w)
     # Cut out the 2x4b LSBs and put each in bits [3:0] of their own 8b words.
-    lsbs = img[::, 2::3].reshape(h,w/2)
+    lsbs = img[::, 2::3].reshape(h,w//2)
     lsbs = numpy.right_shift(
-            numpy.packbits(numpy.unpackbits(lsbs).reshape(h,w/2,2,4),3), 4)
+            numpy.packbits(numpy.unpackbits(lsbs).reshape(h,w//2,2,4),3), 4)
     # Pair the LSB bits group to pixel 0 instead of pixel 1
-    lsbs = lsbs.reshape(h,w/2,2)[:,:,::-1]
+    lsbs = lsbs.reshape(h,w//2,2)[:,:,::-1]
     lsbs = lsbs.reshape(h,w)
     # Fuse the MSBs and LSBs back together
     img16 = numpy.bitwise_or(msbs, lsbs).reshape(h,w)
@@ -250,11 +250,11 @@ def convert_capture_to_planes(cap, props=None):
         cap = unpack_raw12_capture(cap, props)
     if cap["format"] == "yuv":
         y = cap["data"][0:w*h]
-        u = cap["data"][w*h:w*h*5/4]
-        v = cap["data"][w*h*5/4:w*h*6/4]
+        u = cap["data"][w*h:w*h*5//4]
+        v = cap["data"][w*h*5//4:w*h*6//4]
         return ((y.astype(numpy.float32) / 255.0).reshape(h, w, 1),
-                (u.astype(numpy.float32) / 255.0).reshape(h/2, w/2, 1),
-                (v.astype(numpy.float32) / 255.0).reshape(h/2, w/2, 1))
+                (u.astype(numpy.float32) / 255.0).reshape(h//2, w//2, 1),
+                (v.astype(numpy.float32) / 255.0).reshape(h//2, w//2, 1))
     elif cap["format"] == "jpeg":
         rgb = decompress_jpeg_to_rgb_image(cap["data"]).reshape(w*h*3)
         return (rgb[::3].reshape(h,w,1),
@@ -267,9 +267,9 @@ def convert_capture_to_planes(cap, props=None):
                             buffer=cap["data"][0:w*h*2])
         img = img.astype(numpy.float32).reshape(h,w) / white_level
         # Crop the raw image to the active array region.
-        if props.has_key("android.sensor.info.preCorrectionActiveArraySize") \
+        if "android.sensor.info.preCorrectionActiveArraySize" in props \
                 and props["android.sensor.info.preCorrectionActiveArraySize"] is not None \
-                and props.has_key("android.sensor.info.pixelArraySize") \
+                and "android.sensor.info.pixelArraySize" in props \
                 and props["android.sensor.info.pixelArraySize"] is not None:
             # Note that the Rect class is defined such that the left,top values
             # are "inside" while the right,bottom values are "outside"; that is,
@@ -296,10 +296,10 @@ def convert_capture_to_planes(cap, props=None):
             else:
                 raise its.error.Error('Invalid image size metadata')
         # Separate the image planes.
-        imgs = [img[::2].reshape(w*h/2)[::2].reshape(h/2,w/2,1),
-                img[::2].reshape(w*h/2)[1::2].reshape(h/2,w/2,1),
-                img[1::2].reshape(w*h/2)[::2].reshape(h/2,w/2,1),
-                img[1::2].reshape(w*h/2)[1::2].reshape(h/2,w/2,1)]
+        imgs = [img[::2].reshape(w*h//2)[::2].reshape(h//2,w//2,1),
+                img[::2].reshape(w*h//2)[1::2].reshape(h//2,w//2,1),
+                img[1::2].reshape(w*h//2)[::2].reshape(h//2,w//2,1),
+                img[1::2].reshape(w*h//2)[1::2].reshape(h//2,w//2,1)]
         idxs = get_canonical_cfa_order(props)
         return [imgs[i] for i in idxs]
     elif cap["format"] == "rawStats":
@@ -428,7 +428,7 @@ def get_black_level(chan, props, cap_res=None):
     Returns:
         The black level value for the specified channel.
     """
-    if (cap_res is not None and cap_res.has_key('android.sensor.dynamicBlackLevel') and
+    if (cap_res is not None and 'android.sensor.dynamicBlackLevel' in cap_resand and
             cap_res['android.sensor.dynamicBlackLevel'] is not None):
         black_levels = cap_res['android.sensor.dynamicBlackLevel']
     else:
@@ -459,8 +459,8 @@ def convert_yuv420_planar_to_rgb_image(y_plane, u_plane, v_plane,
     y = numpy.subtract(y_plane, yuv_off[0])
     u = numpy.subtract(u_plane, yuv_off[1]).view(numpy.int8)
     v = numpy.subtract(v_plane, yuv_off[2]).view(numpy.int8)
-    u = u.reshape(h/2, w/2).repeat(2, axis=1).repeat(2, axis=0)
-    v = v.reshape(h/2, w/2).repeat(2, axis=1).repeat(2, axis=0)
+    u = u.reshape(h//2, w//2).repeat(2, axis=1).repeat(2, axis=0)
+    v = v.reshape(h//2, w//2).repeat(2, axis=1).repeat(2, axis=0)
     yuv = numpy.dstack([y, u.reshape(w*h), v.reshape(w*h)])
     flt = numpy.empty([h, w, 3], dtype=numpy.float32)
     flt.reshape(w*h*3)[:] = yuv.reshape(h*w*3)[:]
@@ -552,8 +552,8 @@ def load_yuv420_planar_to_yuv_planes(yuv_fname, w, h):
         v = numpy.fromfile(f, numpy.uint8, w*h/4, "")
         u = numpy.fromfile(f, numpy.uint8, w*h/4, "")
         return ((y.astype(numpy.float32) / 255.0).reshape(h, w, 1),
-                (u.astype(numpy.float32) / 255.0).reshape(h/2, w/2, 1),
-                (v.astype(numpy.float32) / 255.0).reshape(h/2, w/2, 1))
+                (u.astype(numpy.float32) / 255.0).reshape(h//2, w//2, 1),
+                (v.astype(numpy.float32) / 255.0).reshape(h//2, w//2, 1))
 
 
 def decompress_jpeg_to_rgb_image(jpeg_buffer):
@@ -565,7 +565,7 @@ def decompress_jpeg_to_rgb_image(jpeg_buffer):
     Returns:
         A numpy array for the RGB image, with pixels in [0,1].
     """
-    img = Image.open(cStringIO.StringIO(jpeg_buffer))
+    img = Image.open(io.StringIO(jpeg_buffer))
     w = img.size[0]
     h = img.size[1]
     return numpy.array(img).reshape(h,w,3) / 255.0
@@ -663,7 +663,7 @@ def compute_image_means(img):
     """
     means = []
     chans = img.shape[2]
-    for i in xrange(chans):
+    for i in range(chans):
         means.append(numpy.mean(img[:,:,i], dtype=numpy.float64))
     return means
 
@@ -679,7 +679,7 @@ def compute_image_variances(img):
     """
     variances = []
     chans = img.shape[2]
-    for i in xrange(chans):
+    for i in range(chans):
         variances.append(numpy.var(img[:,:,i], dtype=numpy.float64))
     return variances
 
@@ -711,7 +711,7 @@ def compute_image_max_gradients(img):
     """
     grads = []
     chans = img.shape[2]
-    for i in xrange(chans):
+    for i in range(chans):
         grads.append(numpy.amax(numpy.gradient(img[:, :, i])))
     return grads
 
@@ -766,16 +766,16 @@ def downscale_image(img, f):
     h,w,chans = img.shape
     f = int(f)
     assert(f >= 1)
-    h = (h/f)*f
-    w = (w/f)*f
+    h = (h//f)*f
+    w = (w//f)*f
     img = img[0:h:,0:w:,::]
     chs = []
-    for i in xrange(chans):
+    for i in range(chans):
         ch = img.reshape(h*w*chans)[i::chans].reshape(h,w)
-        ch = ch.reshape(h,w/f,f).mean(2).reshape(h,w/f)
-        ch = ch.T.reshape(w/f,h/f,f).mean(2).T.reshape(h/f,w/f)
-        chs.append(ch.reshape(h*w/(f*f)))
-    img = numpy.vstack(chs).T.reshape(h/f,w/f,chans)
+        ch = ch.reshape(h,w//f,f).mean(2).reshape(h,w//f)
+        ch = ch.T.reshape(w//f,h//f,f).mean(2).T.reshape(h//f,w//f)
+        chs.append(ch.reshape(h*w//(f*f)))
+    img = numpy.vstack(chs).T.reshape(h//f,w//f,chans)
     return img
 
 
@@ -858,10 +858,10 @@ def stationary_lens_cap(cam, req, fmt):
     done = False
     reqs = [req] * NUM_FRAMES
     while not done:
-        print 'Waiting for lens to move to correct location...'
+        print('Waiting for lens to move to correct location...')
         cap = cam.do_capture(reqs, fmt)
         done = (cap[NUM_FRAMES-1]['metadata']['android.lens.state'] == 0)
-        print ' status: ', done
+        print(' status: ', done)
         trys += 1
         if trys == NUM_TRYS:
             raise its.error.Error('Cannot settle lens after %d trys!' % trys)
@@ -888,7 +888,7 @@ class __UnitTest(unittest.TestCase):
         x = numpy.array([0.1,0.2,0.3]).reshape(1,1,3)
         y = apply_matrix_to_image(x, mat).reshape(3).tolist()
         y_ref = [1.4,3.2,5.0]
-        passed = all([math.fabs(y[i] - y_ref[i]) < 0.001 for i in xrange(3)])
+        passed = all([math.fabs(y[i] - y_ref[i]) < 0.001 for i in range(3)])
         self.assertTrue(passed)
 
     def test_apply_lut_to_image(self):
@@ -899,11 +899,11 @@ class __UnitTest(unittest.TestCase):
 
             lut[x] = 2*x
         """
-        lut = numpy.array([2*i for i in xrange(65536)])
+        lut = numpy.array([2*i for i in range(65536)])
         x = numpy.array([0.1,0.2,0.3]).reshape(1,1,3)
         y = apply_lut_to_image(x, lut).reshape(3).tolist()
         y_ref = [0.2,0.4,0.6]
-        passed = all([math.fabs(y[i] - y_ref[i]) < 0.001 for i in xrange(3)])
+        passed = all([math.fabs(y[i] - y_ref[i]) < 0.001 for i in range(3)])
         self.assertTrue(passed)
 
     def test_unpack_raw10_image(self):
diff --git a/pymodules/its/objects.py b/pymodules/its/objects.py
index a76c7d4..f53e006 100644
--- a/pymodules/its/objects.py
+++ b/pymodules/its/objects.py
@@ -117,7 +117,7 @@ def manual_capture_request(
             req["android.tonemap.mode"] = 3
             req["android.tonemap.gamma"] = 1.0
         else:
-            print "Linear tonemap is not supported"
+            print("Linear tonemap is not supported")
             assert(False)
     return req
 
@@ -196,7 +196,7 @@ def set_filter_off_or_fast_if_possible(props, req, available_modes, filter):
     Returns:
         Nothing.
     """
-    if props.has_key(available_modes):
+    if available_modes in props:
         if 0 in props[available_modes]:
             req[filter] = 0
         elif 1 in props[available_modes]:
@@ -222,12 +222,12 @@ def turn_slow_filters_off(props, req):
     set_filter_off_or_fast_if_possible(props, req,
         "android.colorCorrection.availableAberrationModes",
         "android.colorCorrection.aberrationMode")
-    if props.has_key("camera.characteristics.keys"):
+    if "camera.characteristics.keys" in props:
         chars_keys = props["camera.characteristics.keys"]
         hot_pixel_modes = \
                 "android.hotPixel.availableHotPixelModes" in chars_keys
         edge_modes = "android.edge.availableEdgeModes" in chars_keys
-    if props.has_key("camera.characteristics.requestKeys"):
+    if "camera.characteristics.requestKeys" in props:
         req_keys = props["camera.characteristics.requestKeys"]
         hot_pixel_mode = "android.hotPixel.mode" in req_keys
         edge_mode = "android.edge.mode" in req_keys
@@ -345,7 +345,7 @@ def get_max_digital_zoom(props):
 
     maxz = 1.0
 
-    if props.has_key("android.scaler.availableMaxDigitalZoom"):
+    if "android.scaler.availableMaxDigitalZoom" in props:
         maxz = props["android.scaler.availableMaxDigitalZoom"]
 
     return maxz
diff --git a/pymodules/its/target.py b/pymodules/its/target.py
index 01d3c5f..f7bcd1b 100644
--- a/pymodules/its/target.py
+++ b/pymodules/its/target.py
@@ -51,7 +51,7 @@ def __do_target_exposure_measurement(its_session):
         The measured product of sensitivity and exposure time that results in
             the luma channel of captured shots having an intensity of 0.5.
     """
-    print "Measuring target exposure"
+    print("Measuring target exposure")
 
     # Get AE+AWB lock first, so the auto values in the capture result are
     # populated properly.
@@ -96,7 +96,7 @@ def __set_cached_target_exposure(exposure):
     Args:
         exposure: The value to cache.
     """
-    print "Setting cached target exposure"
+    print("Setting cached target exposure")
     with open(CACHE_FILENAME, "w") as f:
         f.write(json.dumps({"exposure":exposure}))
 
@@ -154,7 +154,7 @@ def get_target_exposure(its_session=None):
         if s == "target":
             cached_exposure = __get_cached_target_exposure()
     if cached_exposure is not None:
-        print "Using cached target exposure"
+        print("Using cached target exposure")
         return cached_exposure
     if its_session is None:
         with its.device.ItsSession() as cam:
diff --git a/tests/scene0/test_camera_properties.py b/tests/scene0/test_camera_properties.py
index dbd528d..b289130 100644
--- a/tests/scene0/test_camera_properties.py
+++ b/tests/scene0/test_camera_properties.py
@@ -27,15 +27,18 @@ def main():
         pprint.pprint(props)
 
         # Test that a handful of required keys are present.
-        assert(props.has_key('android.sensor.info.sensitivityRange'))
-        assert(props.has_key('android.sensor.orientation'))
-        assert(props.has_key('android.scaler.streamConfigurationMap'))
-        assert(props.has_key('android.lens.facing'))
+        assert('android.sensor.info.sensitivityRange' in props)
+        assert('android.sensor.orientation' in props)
+        assert('android.scaler.streamConfigurationMap' in props)
+        assert('android.lens.facing' in props)
+
+        print("JPG sizes:", its.objects.get_available_output_sizes(
+            "jpg", props))
+        print("RAW sizes:", its.objects.get_available_output_sizes(
+            "raw", props))
+        print("YUV sizes:", its.objects.get_available_output_sizes(
+            "yuv", props))
 
-        print "JPG sizes:", its.objects.get_available_output_sizes("jpg", props)
-        print "RAW sizes:", its.objects.get_available_output_sizes("raw", props)
-        print "YUV sizes:", its.objects.get_available_output_sizes("yuv", props)
 
 if __name__ == '__main__':
     main()
-
diff --git a/tests/scene0/test_gyro_bias.py b/tests/scene0/test_gyro_bias.py
index 44be95f..47e8910 100644
--- a/tests/scene0/test_gyro_bias.py
+++ b/tests/scene0/test_gyro_bias.py
@@ -42,7 +42,7 @@ def main():
         its.caps.skip_unless(its.caps.sensor_fusion(props) and
             cam.get_sensors().get("gyro"))
 
-        print "Collecting gyro events"
+        print("Collecting gyro events")
         cam.start_sensor_events()
         time.sleep(5)
         gyro_events = cam.get_sensor_events()["gyro"]
diff --git a/tests/scene0/test_jitter.py b/tests/scene0/test_jitter.py
index 6a156dd..cd071e5 100644
--- a/tests/scene0/test_jitter.py
+++ b/tests/scene0/test_jitter.py
@@ -47,9 +47,9 @@ def main():
         var = sum([d*d for d in deltas_ms]) / len(deltas_ms) - avg * avg
         range0 = min(deltas_ms) - avg
         range1 = max(deltas_ms) - avg
-        print "Average:", avg
-        print "Variance:", var
-        print "Jitter range:", range0, "to", range1
+        print("Average:", avg)
+        print("Variance:", var)
+        print("Jitter range:", range0, "to", range1)
 
         # Draw a plot.
         pylab.plot(range(len(deltas_ms)), deltas_ms)
diff --git a/tests/scene0/test_metadata.py b/tests/scene0/test_metadata.py
index b8949b1..5a0b2af 100644
--- a/tests/scene0/test_metadata.py
+++ b/tests/scene0/test_metadata.py
@@ -36,18 +36,18 @@ def main():
         cap = cam.do_capture(auto_req)
         md = cap["metadata"]
 
-    print "Hardware level"
-    print "  Legacy:", its.caps.legacy(props)
-    print "  Limited:", its.caps.limited(props)
-    print "  Full or better:", its.caps.full_or_better(props)
-    print "Capabilities"
-    print "  Manual sensor:", its.caps.manual_sensor(props)
-    print "  Manual post-proc:", its.caps.manual_post_proc(props)
-    print "  Raw:", its.caps.raw(props)
-    print "  Sensor fusion:", its.caps.sensor_fusion(props)
+    print("Hardware level")
+    print("  Legacy:", its.caps.legacy(props))
+    print("  Limited:", its.caps.limited(props))
+    print("  Full or better:", its.caps.full_or_better(props))
+    print("Capabilities")
+    print("  Manual sensor:", its.caps.manual_sensor(props))
+    print("  Manual post-proc:", its.caps.manual_post_proc(props))
+    print("  Raw:", its.caps.raw(props))
+    print("  Sensor fusion:", its.caps.sensor_fusion(props))
 
     # Test: hardware level should be a valid value.
-    check('props.has_key("android.info.supportedHardwareLevel")')
+    check('"android.info.supportedHardwareLevel" in props')
     check('props["android.info.supportedHardwareLevel"] is not None')
     check('props["android.info.supportedHardwareLevel"] in [0,1,2,3]')
     manual_sensor = its.caps.manual_sensor(props)
@@ -56,28 +56,28 @@ def main():
     # and rollingShutterSkew must be greater than zero and smaller than all
     # of the possible frame durations.
     if manual_sensor:
-        check('md.has_key("android.sensor.frameDuration")')
+        check('"android.sensor.frameDuration" in md')
         check('md["android.sensor.frameDuration"] is not None')
-    check('md.has_key("android.sensor.rollingShutterSkew")')
+    check('"android.sensor.rollingShutterSkew" in md')
     check('md["android.sensor.rollingShutterSkew"] is not None')
     if manual_sensor:
         check('md["android.sensor.rollingShutterSkew"] > 0')
         check('md["android.sensor.frameDuration"] > 0')
 
     # Test: timestampSource must be a valid value.
-    check('props.has_key("android.sensor.info.timestampSource")')
+    check('"android.sensor.info.timestampSource" in props')
     check('props["android.sensor.info.timestampSource"] is not None')
     check('props["android.sensor.info.timestampSource"] in [0,1]')
 
     # Test: croppingType must be a valid value, and for full devices, it
     # must be FREEFORM=1.
-    check('props.has_key("android.scaler.croppingType")')
+    check('"android.scaler.croppingType" in props')
     check('props["android.scaler.croppingType"] is not None')
     check('props["android.scaler.croppingType"] in [0,1]')
 
     # Test: android.sensor.blackLevelPattern exists for RAW and is not None
     if its.caps.raw(props):
-        check('props.has_key("android.sensor.blackLevelPattern")')
+        check('"android.sensor.blackLevelPattern" in props')
         check('props["android.sensor.blackLevelPattern"] is not None')
 
     assert not failed
@@ -89,8 +89,8 @@ def main():
         sensor_size = props["android.sensor.info.physicalSize"]
         pixel_pitch_h = (sensor_size["height"] / fmts[0]["height"] * 1E3)
         pixel_pitch_w = (sensor_size["width"] / fmts[0]["width"] * 1E3)
-        print "Assert pixel_pitch WxH: %.2f um, %.2f um" % (pixel_pitch_w,
-                                                            pixel_pitch_h)
+        print("Assert pixel_pitch WxH: %.2f um, %.2f um" % (pixel_pitch_w,
+                                                            pixel_pitch_h))
         assert 0.7 <= pixel_pitch_w <= 10
         assert 0.7 <= pixel_pitch_h <= 10
         assert 0.333 <= pixel_pitch_w/pixel_pitch_h <= 3.0
@@ -99,14 +99,14 @@ def main():
                          sensor_size["width"] ** 2)
         fl = md["android.lens.focalLength"]
         fov = 2 * math.degrees(math.atan(diag / (2 * fl)))
-        print "Assert field of view: %.1f degrees" % fov
+        print("Assert field of view: %.1f degrees" % fov)
         assert 30 <= fov <= 130
 
         if its.caps.lens_approx_calibrated(props):
             diopter_hyperfocal = props["android.lens.info.hyperfocalDistance"]
             if diopter_hyperfocal != 0.0:
                 hyperfocal = 1.0 / diopter_hyperfocal
-                print "Assert hyperfocal distance: %.2f m" % hyperfocal
+                print("Assert hyperfocal distance: %.2f m" % hyperfocal)
                 assert 0.02 <= hyperfocal
 
 
@@ -123,14 +123,13 @@ def check(expr):
     global md, props, failed
     try:
         if eval(expr):
-            print "Passed>", expr
+            print("Passed>", expr)
         else:
-            print "Failed>>", expr
+            print("Failed>>", expr)
             failed = True
     except:
-        print "Failed>>", expr
+        print("Failed>>", expr)
         failed = True
 
 if __name__ == '__main__':
     main()
-
diff --git a/tests/scene0/test_param_sensitivity_burst.py b/tests/scene0/test_param_sensitivity_burst.py
index b716141..2cf9350 100644
--- a/tests/scene0/test_param_sensitivity_burst.py
+++ b/tests/scene0/test_param_sensitivity_burst.py
@@ -34,7 +34,7 @@ def main():
                              its.caps.per_frame_control(props))
 
         sens_range = props['android.sensor.info.sensitivityRange']
-        sens_step = (sens_range[1] - sens_range[0]) / NUM_STEPS
+        sens_step = (sens_range[1] - sens_range[0]) // NUM_STEPS
         sens_list = range(sens_range[0], sens_range[1], sens_step)
         e = min(props['android.sensor.info.exposureTimeRange'])
         reqs = [its.objects.manual_capture_request(s, e) for s in sens_list]
diff --git a/tests/scene0/test_read_write.py b/tests/scene0/test_read_write.py
index 1b76806..3fdb8ce 100644
--- a/tests/scene0/test_read_write.py
+++ b/tests/scene0/test_read_write.py
@@ -44,8 +44,8 @@ def main():
         # grab exp/gain ranges from camera
         sensor_exp_range = props['android.sensor.info.exposureTimeRange']
         sens_range = props['android.sensor.info.sensitivityRange']
-        print 'sensor e range:', sensor_exp_range
-        print 'sensor s range:', sens_range
+        print('sensor e range:', sensor_exp_range)
+        print('sensor s range:', sens_range)
 
         # determine if exposure test range is within sensor reported range
         exp_range = []
@@ -95,19 +95,21 @@ def main():
 
         # print results
         if e_failed:
-            print '\nFAILs for exposure time'
+            print('\nFAILs for exposure time')
             for fail in e_failed:
-                print ' e_write: %d, e_read: %d, RTOL: %.2f, ' % (
-                        fail['e_write'], fail['e_read'], RTOL_EXP_GAIN),
-                print 's_write: %d, s_read: %d, RTOL: %.2f' % (
-                        fail['s_write'], fail['s_read'], RTOL_EXP_GAIN)
+                print(' e_write: %d, e_read: %d, RTOL: %.2f, ' %
+                      (fail['e_write'], fail['e_read'], RTOL_EXP_GAIN),
+                      end='')
+                print('s_write: %d, s_read: %d, RTOL: %.2f' %
+                      (fail['s_write'], fail['s_read'], RTOL_EXP_GAIN))
         if s_failed:
-            print 'FAILs for sensitivity(ISO)'
+            print('FAILs for sensitivity(ISO)')
             for fail in s_failed:
-                print 's_write: %d, s_read: %d, RTOL: %.2f, ' % (
-                        fail['s_write'], fail['s_read'], RTOL_EXP_GAIN),
-                print ' e_write: %d, e_read: %d, RTOL: %.2f' % (
-                        fail['e_write'], fail['e_read'], RTOL_EXP_GAIN)
+                print('s_write: %d, s_read: %d, RTOL: %.2f, ' %
+                      (fail['s_write'], fail['s_read'], RTOL_EXP_GAIN),
+                      end='')
+                print(' e_write: %d, e_read: %d, RTOL: %.2f' %
+                      (fail['e_write'], fail['e_read'], RTOL_EXP_GAIN))
 
         # assert PASS/FAIL
         assert not e_failed+s_failed
diff --git a/tests/scene0/test_sensor_events.py b/tests/scene0/test_sensor_events.py
index d3226b3..e398aab 100644
--- a/tests/scene0/test_sensor_events.py
+++ b/tests/scene0/test_sensor_events.py
@@ -32,8 +32,8 @@ def main():
         cam.start_sensor_events()
         time.sleep(1)
         events = cam.get_sensor_events()
-        print "Events over 1s: %d gyro, %d accel, %d mag"%(
-                len(events["gyro"]), len(events["accel"]), len(events["mag"]))
+        print("Events over 1s: %d gyro, %d accel, %d mag" %
+              (len(events["gyro"]), len(events["accel"]), len(events["mag"])))
         for key, existing in sensors.iteritems():
             if existing:
                 e_msg = 'Sensor %s has no events!' % key
@@ -41,4 +41,3 @@ def main():
 
 if __name__ == '__main__':
     main()
-
diff --git a/tests/scene0/test_test_patterns.py b/tests/scene0/test_test_patterns.py
index a1d9cb8..3614a1a 100644
--- a/tests/scene0/test_test_patterns.py
+++ b/tests/scene0/test_test_patterns.py
@@ -40,7 +40,7 @@ def check_solid_color(cap, props):
     Returns:
         True/False
     """
-    print 'Checking solid TestPattern...'
+    print('Checking solid TestPattern...')
     r, gr, gb, b = its.image.convert_capture_to_planes(cap, props)
     r_tile = its.image.get_image_patch(r, 0.0, 0.0, 1.0, 1.0)
     gr_tile = its.image.get_image_patch(gr, 0.0, 0.0, 1.0, 1.0)
@@ -51,8 +51,8 @@ def check_solid_color(cap, props):
     var_min = min(np.amin(r_tile), np.amin(gr_tile), np.amin(gb_tile),
                   np.amin(b_tile))
     white_level = int(props['android.sensor.info.whiteLevel'])
-    print ' pixel min: %.f, pixel max: %.f' % (white_level*var_min,
-                                               white_level*var_max)
+    print(' pixel min: %.f, pixel max: %.f' % (white_level * var_min,
+                                               white_level * var_max))
     return np.isclose(var_max, var_min, atol=CH_TOL)
 
 
@@ -68,21 +68,21 @@ def check_color_bars(cap, props, mirror=False):
     Returns:
         True/False
     """
-    print 'Checking color bar TestPattern...'
+    print('Checking color bar TestPattern...')
     delta = 0.0005
     num_bars = len(COLOR_BAR_ORDER)
     color_match = []
     img = its.image.convert_capture_to_rgb_image(cap, props=props)
     if mirror:
-        print ' Image mirrored'
+        print(' Image mirrored')
         img = np.fliplr(img)
     for i, color in enumerate(COLOR_BAR_ORDER):
         tile = its.image.get_image_patch(img, float(i)/num_bars+delta,
                                          0.0, 1.0/num_bars-2*delta, 1.0)
         color_match.append(np.allclose(its.image.compute_image_means(tile),
                                        COLOR_CHECKER[color], atol=CH_TOL))
-    print COLOR_BAR_ORDER
-    print color_match
+    print(COLOR_BAR_ORDER)
+    print(color_match)
     return all(color_match)
 
 
@@ -109,7 +109,7 @@ def check_pattern(cap, props, pattern):
         return striped
 
     else:
-        print 'No specific test for TestPattern %d' % pattern
+        print('No specific test for TestPattern %d' % pattern)
         return True
 
 
@@ -123,7 +123,7 @@ def test_test_patterns(cam, props, af_fd):
     """
 
     avail_patterns = props['android.sensor.availableTestPatternModes']
-    print 'avail_patterns: ', avail_patterns
+    print('avail_patterns: ', avail_patterns)
     sens_min, _ = props['android.sensor.info.sensitivityRange']
     exposure = min(props['android.sensor.info.exposureTimeRange'])
 
@@ -143,7 +143,7 @@ def test_test_patterns(cam, props, af_fd):
             # Check pattern for correctness
             assert check_pattern(cap, props, pattern)
         else:
-            print 'Pattern not in android.sensor.availableTestPatternModes.'
+            print('Pattern not in android.sensor.availableTestPatternModes.')
 
 
 def main():
@@ -159,7 +159,7 @@ def main():
     4: PN9
     """
 
-    print '\nStarting %s' % NAME
+    print('\nStarting %s' % NAME)
     with its.device.ItsSession() as cam:
         props = cam.get_camera_properties()
         its.caps.skip_unless(its.caps.raw16(props) and
diff --git a/tests/scene0/test_unified_timestamps.py b/tests/scene0/test_unified_timestamps.py
index 5a9228e..27bf347 100644
--- a/tests/scene0/test_unified_timestamps.py
+++ b/tests/scene0/test_unified_timestamps.py
@@ -37,7 +37,7 @@ def main():
         ts_image0 = cap['metadata']['android.sensor.timestamp']
 
         # Get the timestamps of motion events.
-        print "Reading sensor measurements"
+        print("Reading sensor measurements")
         sensors = cam.get_sensors()
         cam.start_sensor_events()
         time.sleep(2.0)
@@ -54,16 +54,16 @@ def main():
         cap = cam.do_capture(req, fmt)
         ts_image1 = cap['metadata']['android.sensor.timestamp']
 
-        print "Image timestamps:", ts_image0, ts_image1
+        print("Image timestamps:", ts_image0, ts_image1)
 
         # The motion timestamps must be between the two image timestamps.
         for sensor, existing in sensors.iteritems():
             if existing:
-                print "%s timestamps: %d %d" % (sensor, ts_sensor_first[sensor],
-                                                ts_sensor_last[sensor])
+                print("%s timestamps: %d %d" %
+                      (sensor, ts_sensor_first[sensor],
+                       ts_sensor_last[sensor]))
                 assert ts_image0 < ts_sensor_first[sensor] < ts_image1
                 assert ts_image0 < ts_sensor_last[sensor] < ts_image1
 
 if __name__ == '__main__':
     main()
-
diff --git a/tools/run_all_tests.py b/tools/run_all_tests.py
index b6fdde2..d20cdda 100644
--- a/tools/run_all_tests.py
+++ b/tools/run_all_tests.py
@@ -79,7 +79,7 @@ def calc_camera_fov(camera_id):
         props = cam.get_camera_properties()
         focal_ls = props['android.lens.info.availableFocalLengths']
         if len(focal_ls) > 1:
-            print 'Doing capture to determine logical camera focal length'
+            print('Doing capture to determine logical camera focal length')
             cap = cam.do_capture(its.objects.auto_capture_request())
             focal_l = cap['metadata']['android.lens.focalLength']
         else:
@@ -91,7 +91,7 @@ def calc_camera_fov(camera_id):
         fov = str(round(2 * math.degrees(math.atan(diag / (2 * focal_l))), 2))
     except ValueError:
         fov = str(0)
-    print 'Calculated FoV: %s' % fov
+    print('Calculated FoV: %s' % fov)
     return fov
 
 
@@ -228,7 +228,7 @@ def main():
                     break
 
         if not valid_scenes:
-            print 'Unknown scene specified:', s
+            print('Unknown scene specified:', s)
             assert False
         scenes = temp_scenes
 
@@ -241,11 +241,11 @@ def main():
     # Make output directories to hold the generated files.
     topdir = tempfile.mkdtemp(dir=tmp_dir)
     subprocess.call(['chmod', 'g+rx', topdir])
-    print "Saving output files to:", topdir, "\n"
+    print("Saving output files to:", topdir, "\n")
 
     device_id = its.device.get_device_id()
     device_id_arg = "device=" + device_id
-    print "Testing device " + device_id
+    print("Testing device " + device_id)
 
     # Sanity Check for devices
     device_bfp = its.device.get_device_fingerprint(device_id)
@@ -266,17 +266,17 @@ def main():
         with its.device.ItsSession() as cam:
             camera_ids = cam.get_camera_ids()
 
-    print "Running ITS on camera: %s, scene %s" % (camera_ids, scenes)
+    print("Running ITS on camera: %s, scene %s" % (camera_ids, scenes))
 
     if auto_scene_switch:
         # merge_result only supports run_parallel_tests
         if merge_result_switch and camera_ids[0] == '1':
-            print 'Skip chart screen'
+            print('Skip chart screen')
             time.sleep(1)
         else:
-            print 'Waking up chart screen: ', chart_host_id
+            print('Waking up chart screen: ', chart_host_id)
             screen_id_arg = ('screen=%s' % chart_host_id)
-            cmd = ['python', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
+            cmd = ['python3', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
                                           'wake_up_screen.py'), screen_id_arg]
             wake_code = subprocess.call(cmd)
             assert wake_code == 0
@@ -285,7 +285,7 @@ def main():
         camera_fov = calc_camera_fov(camera_id)
         # Loop capturing images until user confirm test scene is correct
         camera_id_arg = "camera=" + camera_id
-        print "Preparing to run ITS on camera", camera_id
+        print("Preparing to run ITS on camera", camera_id)
 
         os.mkdir(os.path.join(topdir, camera_id))
         for d in scenes:
@@ -321,7 +321,7 @@ def main():
                             (merge_result_switch and camera_ids[0] == '0')):
                         scene_arg = 'scene=' + scene
                         fov_arg = 'fov=' + camera_fov
-                        cmd = ['python',
+                        cmd = ['python3',
                                os.path.join(os.getcwd(), 'tools/load_scene.py'),
                                scene_arg, chart_dist_arg, fov_arg, screen_id_arg]
                     else:
@@ -331,7 +331,7 @@ def main():
                     if validate_switch and not merge_result_switch:
                         scene_arg = 'scene=' + scene_req[scene]
                         extra_args = scene_extra_args.get(scene, [])
-                        cmd = ['python',
+                        cmd = ['python3',
                                os.path.join(os.getcwd(),
                                             'tools/validate_scene.py'),
                                camera_id_arg, out_arg,
@@ -339,7 +339,7 @@ def main():
                 if cmd is not None:
                     valid_scene_code = subprocess.call(cmd, cwd=topdir)
                     assert valid_scene_code == 0
-            print "Start running ITS on camera %s, %s" % (camera_id, scene)
+            print("Start running ITS on camera %s, %s" % (camera_id, scene))
             # Extract chart from scene for scene3 once up front
             chart_loc_arg = ''
             chart_height = CHART_HEIGHT
@@ -375,16 +375,16 @@ def main():
                     if scene == 'sensor_fusion':
                         if skip_code is not SKIP_RET_CODE:
                             if rot_rig_id:
-                                print 'Rotating phone w/ rig %s' % rot_rig_id
-                                rig = ('python tools/rotation_rig.py rotator=%s' %
+                                print('Rotating phone w/ rig %s' % rot_rig_id)
+                                rig = ('python3 tools/rotation_rig.py rotator=%s' %
                                        rot_rig_id)
                                 subprocess.Popen(rig.split())
                             else:
-                                print 'Rotate phone 15s as shown in SensorFusion.pdf'
+                                print('Rotate phone 15s as shown in SensorFusion.pdf')
                         else:
                             test_code = skip_code
                     if skip_code is not SKIP_RET_CODE:
-                        cmd = ['python', os.path.join(os.getcwd(), testpath)]
+                        cmd = ['python3', os.path.join(os.getcwd(), testpath)]
                         cmd += sys.argv[1:] + [camera_id_arg] + [chart_loc_arg]
                         cmd += [chart_dist_arg]
                         with open(outpath, 'w') as fout, open(errpath, 'w') as ferr:
@@ -396,7 +396,7 @@ def main():
                         socket_fail = evaluate_socket_failure(errpath)
                         if socket_fail:
                             if num_try != NUM_TRYS-1:
-                                print ' Retry %s/%s' % (scene, testname)
+                                print(' Retry %s/%s' % (scene, testname))
                             else:
                                 break
                         else:
@@ -419,7 +419,7 @@ def main():
                     test_failed = True
 
                 msg = "%s %s/%s [%.1fs]" % (retstr, scene, testname, t1-t0)
-                print msg
+                print(msg)
                 its.device.adb_log(device_id, msg)
                 msg_short = "%s %s [%.1fs]" % (retstr, testname, t1-t0)
                 if test_failed:
@@ -439,11 +439,11 @@ def main():
                 100.0 * float(numpass + num_not_mandated_fail) /
                 (len(tests) - numskip)
                 if len(tests) != numskip else 100.0, skipstr)
-            print test_result
+            print(test_result)
 
             if num_not_mandated_fail > 0:
                 msg = "(*) tests are not yet mandated"
-                print msg
+                print(msg)
 
             summary_path = os.path.join(topdir, camera_id, scene, "summary.txt")
             with open(summary_path, "w") as f:
@@ -457,7 +457,7 @@ def main():
             results[scene][ItsSession.END_TIME_KEY] = scene_end_time
 
         msg = "Reporting ITS result to CtsVerifier"
-        print msg
+        print(msg)
         its.device.adb_log(device_id, msg)
         if merge_result_switch:
             # results are modified by report_result
@@ -468,23 +468,23 @@ def main():
 
     if auto_scene_switch:
         if merge_result_switch:
-            print 'Skip shutting down chart screen'
+            print('Skip shutting down chart screen')
         else:
-            print 'Shutting down chart screen: ', chart_host_id
+            print('Shutting down chart screen: ', chart_host_id)
             screen_id_arg = ('screen=%s' % chart_host_id)
-            cmd = ['python', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
+            cmd = ['python3', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
                                           'turn_off_screen.py'), screen_id_arg]
             screen_off_code = subprocess.call(cmd)
             assert screen_off_code == 0
 
-            print 'Shutting down DUT screen: ', device_id
+            print('Shutting down DUT screen: ', device_id)
             screen_id_arg = ('screen=%s' % device_id)
-            cmd = ['python', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
+            cmd = ['python3', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
                                           'turn_off_screen.py'), screen_id_arg]
             screen_off_code = subprocess.call(cmd)
             assert screen_off_code == 0
 
-    print "ITS tests finished. Please go back to CtsVerifier and proceed"
+    print("ITS tests finished. Please go back to CtsVerifier and proceed")
 
 if __name__ == '__main__':
     main()
diff --git a/tools/run_parallel_tests.py b/tools/run_parallel_tests.py
index cdba01e..01d962c 100644
--- a/tools/run_parallel_tests.py
+++ b/tools/run_parallel_tests.py
@@ -89,7 +89,7 @@ def build_cmd(device_id, chart_host_id, result_device_id, camera_id, scene_id):
     """ Create a cmd list for run_all_tests.py
     Return a list of cmd & parameters
     """
-    cmd = ['python',
+    cmd = ['python3',
             os.path.join(os.getcwd(),'tools/run_all_tests.py'),
             'device=%s' % device_id,
             'result=%s' % result_device_id,
@@ -120,7 +120,7 @@ def shut_down_device_screen(device_id):
 
     print 'Shutting down chart screen: ', device_id
     screen_id_arg = ('screen=%s' % device_id)
-    cmd = ['python', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
+    cmd = ['python3', os.path.join(os.environ['CAMERA_ITS_TOP'], 'tools',
                                   'turn_off_screen.py'), screen_id_arg]
     retcode = subprocess.call(cmd)
     assert retcode == 0
diff --git a/tools/run_sensor_fusion_box.py b/tools/run_sensor_fusion_box.py
index 3c9199a..f8c3106 100644
--- a/tools/run_sensor_fusion_box.py
+++ b/tools/run_sensor_fusion_box.py
@@ -119,9 +119,9 @@ def main():
     shift_list = []
     for i in range(num_runs):
         os.mkdir(os.path.join(tmpdir, camera_id, SCENE_NAME+'_'+str(i)))
-        cmd = 'python tools/rotation_rig.py rotator=%s' % rotator_ids
+        cmd = 'python3 tools/rotation_rig.py rotator=%s' % rotator_ids
         subprocess.Popen(cmd.split())
-        cmd = ['python', os.path.join(TEST_DIR, TEST_NAME+'.py'),
+        cmd = ['python3', os.path.join(TEST_DIR, TEST_NAME+'.py'),
                device_id_arg, camera_id_arg, rotator_id_arg, img_size_arg,
                fps_arg, test_length_arg]
         outdir = os.path.join(tmpdir, camera_id, SCENE_NAME+'_'+str(i))
