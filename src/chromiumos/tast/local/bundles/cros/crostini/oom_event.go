// Copyright 2022 The Chromium OS Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

package crostini

import (
	"context"
	"time"

	"github.com/godbus/dbus"

	"chromiumos/tast/common/testexec"
	"chromiumos/tast/ctxutil"
	"chromiumos/tast/errors"
	"chromiumos/tast/local/chrome"
	"chromiumos/tast/local/chrome/metrics"
	"chromiumos/tast/local/crash"
	"chromiumos/tast/local/crostini"
	"chromiumos/tast/local/dbusutil"
	"chromiumos/tast/local/vm"
	"chromiumos/tast/testing"
)

const (
	oomAnomalyEventServiceName              = "org.chromium.AnomalyEventService"
	oomAnomalyEventServicePath              = dbus.ObjectPath("/org/chromium/AnomalyEventService")
	oomAnomalyEventServiceInterface         = "org.chromium.AnomalyEventServiceInterface"
	oomAnomalyGuestFileCorruptionSignalName = "GuestOomEvent"
	crosEventHistogram                      = "Platform.CrOSEvent"
	oomEventHistogram                       = "Crostini.OomEvent"

	killCode = 9
)

func init() {
	testing.AddTest(&testing.Test{
		Func:         OOMEvent,
		LacrosStatus: testing.LacrosVariantUnneeded,
		Desc:         "Check that OOM kill by kernel is detected correctly",
		Contacts: []string{
			// Crosvm
			"drmasquatch@google.com",
			// Telemetry
			"mutexlox@google.com",
			"cros-telemetry@google.com",
		},
		SoftwareDeps: []string{"chrome", "vm_host"},
		Attr:         []string{"group:mainline", "informational"},
		Params: []testing.Param{
			// Parameters generated by params_test.go. DO NOT EDIT.
			{
				Name:              "stable",
				ExtraSoftwareDeps: []string{"dlc"},
				ExtraHardwareDeps: crostini.CrostiniStable,
				Fixture:           "crostiniBuster",
				Timeout:           10 * time.Minute,
			}, {
				Name:              "unstable",
				ExtraAttr:         []string{"informational"},
				ExtraSoftwareDeps: []string{"dlc"},
				ExtraHardwareDeps: crostini.CrostiniUnstable,
				Fixture:           "crostiniBuster",
				Timeout:           10 * time.Minute,
			},
		},
	})
}

// OOMEvent sets up the VM and then runs a process which will be killed via
// the kernels OOM killer to check that it is detected correctly.
func OOMEvent(ctx context.Context, s *testing.State) {
	pre := s.FixtValue().(crostini.FixtureData)
	cont := pre.Cont
	tconn := pre.Tconn

	// Use a shortened context for the test to reserver time for cleanup.
	cleanupCtx := ctx
	ctx, cancel := ctxutil.Shorten(ctx, 5*time.Second)
	defer cancel()

	s.Log("Setting up crash test")
	if err := crash.SetUpCrashTest(ctx, crash.WithMockConsent()); err != nil {
		s.Fatal("Failed to set up crash test: ", err)
	}
	defer func() {
		if err := crash.TearDownCrashTest(cleanupCtx); err != nil {
			s.Error("Failed to tear down crash test fixture: ", err)
		}
	}()

	// histogramCount, err := checkOomHistogram(ctx, tconn, -1, s)
	histogramCount, hist, err := checkOomHistogram(ctx, tconn, -1, s)
	if err != nil {
		s.Fatal("Failed to get baseline for histogram: ", err)
	}

	if err := checkDbusSignal(ctx, cont, s); err != nil {
		s.Fatal("Didn't get an error signal for OOM process: ", err)
	}

	newhist, err := metrics.WaitForHistogramUpdate(ctx, tconn, crosEventHistogram, hist, 10*time.Second)
	if err != nil {
		s.Fatal("Couldn't get update: ", err)
	}
	if newhist.Sum <= histogramCount {
		s.Fatalf("Expected total of more than %v histogram values, got %v", histogramCount, newhist.Sum)
	}

	// histogramCount, err = checkOomHistogram(ctx, tconn, histogramCount, s)
	// if err != nil {
	// 	s.Fatal("Failed to check histogram: ", err)
	// }
}

func checkOomHistogram(ctx context.Context, tconn *chrome.TestConn, baseline int64, s *testing.State) (int64, *metrics.Histogram, error) {
	hist, err := metrics.GetHistogram(ctx, tconn, crosEventHistogram)
	s.Log("++++++++++++")
	s.Log(hist.String())
	s.Log("++++++++++++")
	if err != nil {
		return 0, hist, err
	}
	if hist.Sum <= baseline {
		return hist.Sum, hist, errors.Errorf("expected total of more than %v histogram values, got %v", baseline, hist.Sum)
	}
	return hist.Sum, hist, nil
}

func checkDbusSignal(ctx context.Context, container *vm.Container, s *testing.State) (resultError error) {
	match := dbusutil.MatchSpec{
		Type:      "signal",
		Path:      oomAnomalyEventServicePath,
		Interface: oomAnomalyEventServiceInterface,
		Member:    oomAnomalyGuestFileCorruptionSignalName,
	}
	signalWatcher, err := dbusutil.NewSignalWatcherForSystemBus(ctx, match)
	if err != nil {
		return errors.Wrap(err, "failed to listen for DBus signals")
	}
	defer func() {
		if err := signalWatcher.Close(ctx); err != nil {
			if resultError == nil {
				resultError = err
			} else {
				testing.ContextLog(ctx, "Failed to close signal watcher: ", err)
			}
		}
	}()

	s.Log("Starting tail process")
	// tail will buffer input in-memory until it reaches a newline, so it can
	// print at least one line at a time. Since /dev/zero by definition has no
	// newlines, the memory of the process should expand until eventually the
	// kernel will be forced to kill it.
	cmd := container.VM.Command(ctx, "tail", "/dev/zero")
	code, extracted := testexec.ExitCode(cmd.Run())
	if !extracted {
		s.Fatal("Failed to extract exit code from running tail ")
	}
	if code != killCode {
		s.Fatalf("Failed to fail correctly, expected process to exit with code %v, exited with %v instead", killCode, code)
	}

	testing.ContextLog(ctx, "Waiting for signal from anomaly_detector")
	signalCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	if _, err := waitForAnomalyDetectorSignal(signalCtx, signalWatcher); err != nil {
		return errors.Wrap(err, "didn't get expected DBus signal")
	}
	testing.ContextLog(ctx, "Got expected signal from anomaly_detector")

	return nil
}

func waitForAnomalyDetectorSignal(ctx context.Context, signalWatcher *dbusutil.SignalWatcher) (*dbus.Signal, error) {
	select {
	case signal := <-signalWatcher.Signals:
		return signal, nil
	case <-ctx.Done():
		return nil, errors.New("Context deadline expired")
	}
}
